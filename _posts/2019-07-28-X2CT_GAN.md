---
1ayout: post
update: 2019-07-28 23:03:00 +0800
title:  X2CT-GAN Reconstructing CT from Biplanar X-Rays with Generative Adversarial Networks
categories: Summary
tags: [Gan,DN]
abstract: 这篇文章很好的介绍了如何使用Gan网络做医学图像分割
mathjax: true
gitment: true
---
* TOC
{:toc}
* # 一、解决了什么问题？
  
    *  1.   1. 通过两张正交的X光就能重建CT模型
    
    			* CT的成本比X光更贵
    
    			* 经典的CT重建算法需要数百张X光图片才能还原CT图像
    			* 经过实验，两张正交的X光还原的CT模型比单张的X光还原效果好
    
    		2. 提出了X2CT-GAN的结构
    
    			* 输入的X光是2维数据，而输出的CT图像是3D模型。
    			* 由于多数不透明光图片只能用来生产表面图像，而X光可以穿透人体，所以可以连血管等内部组织也能被一起重建。
    			* 除了胸腔还能重建其他器官
    
    		3. 提出了一种新颖的跳跃连接模型，让2D和3D数据特征图像更自然
    
    		4. CycleGAN被用来创建训练数据，实现两个不成对的训练数据之间的映射(由于没有现成的X光以及配套的CT模型)
    
    		5. 与其他可见光重构相比，我们可以重建表面和内部结构
    
* # 二、X2CT-GAN的损失函数
  
    * <div  class='image'>
        <img src='/assets/images/posts/2019/07/28/using_loss.gif' alt='Loss函数使用说明书'/>
        <div class='image_alt'>Loss函数使用说明书</div>
      </div>
      
    * ## 1. Adversarial Loss
    
        * 由于需要学习一个从X光到CT的非线性映射。经过实验，发现LSGAN得到的效果最好。
        * <div  class='image'>
            <img src='/assets/images/posts/2019/07/28/LSGAN_Loss.gif' alt='LSGAN Loss'/>
            <div class='image_alt'>LSGAN Loss</div>
          </div>
        * 其中X是两个正交的X光组合，样式响应的CT模型
    
    * ## 2. Reconstruction Loss
    
        * 采用的是MSE，这是G的Loss
        * <div  class='image'>
            <img src='/assets/images/posts/2019/07/28/reconstruction_loss.gif' alt='Reconstruction Loss'/>
            <div class='image_alt'>Reconstruction Loss</div>
          </div>
    
    * ## 3. Projection Loss
    
        * 3DLoss可以提高3D模型的空间一致性，而2D图像的损失函数可以用来做辅助的Loss。
        * <div  class='image'>
            <img src='/assets/images/posts/2019/07/28/projection_loss.gif' alt='Projection Loss'/>
            <div class='image_alt'>Projection Loss</div>
          </div>
    
    * ## 4. Total Loss
    
        * <div  class='image'>
            <img src='/assets/images/posts/2019/07/28/total_loss.gif' alt='Total Loss'/>
            <div class='image_alt'>Total Loss</div>
          </div>
    
* # 三、X2CT-GAN的网络结构
  
    * ## 1.生成器的组成
    
        * <div  class='image'>
            <img src='/assets/images/posts/2019/07/28/generate.gif' alt='生成器组成图'/>
            <div class='image_alt'>生成器组成图</div>
          </div>
        * 通过Dense来进行编码提取特征值
        * 连接2D编码和3D解码
            *   <div  class='image'>
                    <img src='/assets/images/posts/2019/07/28/connection.gif' alt='连接说明图'/>
                    <div class='image_alt'>连接说明图</div>
                 </div>
        * 将两行2D网络融合到一起给出新的内容
            *   <div  class='image'>
                    <img src='/assets/images/posts/2019/07/28/connection-c.gif' alt='connection-C说明图'/>
                    <div class='image_alt'>connection-C说明图</div>
                 </div>
    
    * ## 2.诊断网络的组成
    
        *   | 模型 | 参数 |
        	| :----: | :----: |
        	| conv3d-norm-relu | stride=2;kernelsize=4 |
        	| conv3d-norm-relu | stride=2;kernelsize=4 |
        	| conv3d | 无 |
    
    * ## 3.训练过程的细节
    
        1.  优化器:Adam
        2.  learning rate: $2e^{-4}$
        3.  动量参数:$\beta_1=0.5$,$\beta_2=0.99$
        4.  训练50个时期后，采用线性学习率衰减策略将学习率降低到0，总共100个时期。
        5.  batch size=1(作者说是受GPU内存限制约束)
    
* # 四、实验
  
    * ## 1.数据集
      
        * 使用的是LIDC-IDRI数据集(包含1018次胸部CT扫描，912个CT图像用来训练，102个CT图像用来测试)
        * 将数据集重新采样分辨率为 $1\times1\times1 mm^3$
        * 从每个CT扫描中裁剪为 $320\times320\times320 mm^3$
        * (DRR合成的X光线非常逼真，但在血管等微妙的结构还有差异) 
        * 建议将真实的X光映射成合成的X光再来训练，文章说如果用真实的X光图像会得到次优的结果？
        * 由于没有真实和合成X光的配对数据集，所以收集200个真实的X光，用CycleGAN去学习映射，并从配对的LIDC数据集的训练集中随即选择200个合成X光。
    * ## 2. 评估标准
      
        *   **PSNR** 评估重构数字信号的质量
        *   **SSIM** 衡量两幅图像相似度的标准(包括亮度，对比度和结构)
    * ## 3. 结果
      
        *   <div  class='image'>
                <img src='/assets/images/posts/2019/07/28/result_show.gif' alt='结果展示图1'/>
                <div class='image_alt'>结果展示图1</div>
             </div>
        *   其中X2CT-CNN是仅由重建损失监督的拟议网络，而X2CTGAN是完全目标训练的; '+ S'表示单视图X射线输入，'+ B'表示双平面X射线输入。为了进行比较，我们还重现了[2]中提出的方法（在图6中称为2DCNN）作为基线，这是使用深度学习解决X射线到CT重建问题的极少数已发表的工作之一。由于2DCNN设计用于处理单个X射线输入，因此未显示双平面结果。从视觉质量评估中可以看出差异。首先，2DCNN和X2CT-CNN产生非常模糊的体积，而X2CTGAN保持小的解剖结构。其次，虽然缺少重建细节，但是X2CT-CNN + S产生比2DCNN更大的器官（例如，心脏，肺和胸壁）的边界。最后但并非最不重要的是，使用双平面X射线训练的模型优于使用单视图X射线训练的模型。在图8中可以找到更多重建的CT切片。
        *   <div  class='image'>
                <img src='/assets/images/posts/2019/07/28/result_show2.gif' alt='结果展示图2'/>
                <div class='image_alt'>结果展示图2</div>
             </div>
        *   <div  class='image'>
                <img src='/assets/images/posts/2019/07/28/result_show3.gif' alt='结果展示图3'/>
                <div class='image_alt'>结果展示图3</div>
             </div>
        *   <div  class='image'>
                <img src='/assets/images/posts/2019/07/28/table1.gif' alt='数据结果1'/>
                <div class='image_alt'>数据结果1</div>
             </div>
        *   <div  class='image'>
                <img src='/assets/images/posts/2019/07/28/table2.gif' alt='数据结果2'/>
                <div class='image_alt'>数据结果2</div>
             </div>
        *   <div  class='image'>
                <img src='/assets/images/posts/2019/07/28/table3.gif' alt='数据结果3'/>
                <div class='image_alt'>数据结果3</div>
             </div>

    
* # 五、分析
  
    1.  1. 带具体分析
    
* # 六、疑问
    
    1.  1. 训练数据产生的过程？(待研究CycleGAN)
    	2. 为什么合成的数据反而比真实的数据好？
    	3. 最后的结果看不懂，为什么X2CT-CNN+B反而比X2CT-GAN+B的效果好？
    
* # 参考文献

1.  1. [X2CT-GAN: Reconstructing CT from Biplanar X-Rays with Generative Adversarial Networks](http://openaccess.thecvf.com/content_CVPR_2019/papers/Ying_X2CT-GAN_Reconstructing_CT_From_Biplanar_X-Rays_With_Generative_Adversarial_Networks_CVPR_2019_paper.pdf)
	2. [Singleimage tomography: 3D volumes from 2D X-rays](https://arxiv.org/pdf/1710.04867.pdf)

